{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics Tutorial\n",
    "\n",
    "The purpose of this tutorial is to introduce the basics of the Rekall API and\n",
    "show how Rekall queries, together with the Vgrid visualization interface, can\n",
    "be used for video analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "We first need to make sure that `rekall`, `vgrid`, and `vgrid_jupyter` are installed properly. If the following cell runs without error, you're all set. If not, make sure that you've followed the install instructions for [`rekall`](https://github.com/scanner-research/rekall), [`vgrid`](https://github.com/scanner-research/vgrid), and [`vgrid_jupyter`](https://github.com/scanner-research/vgrid_jupyter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from rekall import Interval, IntervalSet, IntervalSetMapping, Bounds3D\n",
    "from rekall.predicates import *\n",
    "from vgrid import VGridSpec, VideoMetadata, VideoBlockFormat, FlatFormat\n",
    "from vgrid_jupyter import VGridWidget\n",
    "import urllib3, requests, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview\n",
    "\n",
    "Let's first take a look at what the end product will look like (this cell will take about **20 seconds** to load all the data from olimar.stanford.edu and visualize it).\n",
    "\n",
    "You should see something like this:\n",
    "\n",
    "![vgrid_preview](https://olimar.stanford.edu/hdd/rekall_tutorials/basics/vgrid_preview.png)\n",
    "\n",
    "### Once the visualization is up, hover over a cell and press `=` to expand it. Hover and use `Shift+p` or `;` to play/pause the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cbffe76f3e46c296ea1cc36cdddec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xbc\\xbd\\xdb\\xae\\xac\\xc9u\\xa5\\xf7*B]\\xb3\\x898\\x1f|\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hack to disable warnings about olimar's certificate\n",
    "urllib3.disable_warnings()\n",
    "VIDEO_COLLECTION_BASEURL = \"https://olimar.stanford.edu/hdd/rekall_tutorials/basics/\"\n",
    "VIDEO_METADATA_FILENAME = 'video_metadata.json'\n",
    "\n",
    "# Load video file metadata\n",
    "video_metadata = [ VideoMetadata(v['filename'], id=v['filename'], fps=v['fps'],\n",
    "                                 num_frames=v['num_frames'], width=v['width'], height=v['height'])\n",
    "                  for v in requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME),\n",
    "                                        verify=False).json() ]\n",
    "\n",
    "# Load bounding boxes from JSON\n",
    "metadata_files = [ 'driving1.json', 'driving2.json', 'driving3.json', 'driving4.json' ]\n",
    "driving_metadata = [ requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, metadata_file),\n",
    "                                  verify=False).json()\n",
    "                    for metadata_file in metadata_files ]\n",
    "\n",
    "# Load bounding boxes into Rekall\n",
    "path2fps = { vm.id: vm.fps for vm in video_metadata }\n",
    "bbox_ism = IntervalSetMapping({\n",
    "    video_file: IntervalSet([\n",
    "        Interval(Bounds3D(t1=f['frame'] / path2fps[video_file], t2=(f['frame'] + 1) / path2fps[video_file],\n",
    "                          x1=bbox['x1'], x2=bbox['x2'], y1=bbox['y1'], y2=bbox['y2']),\n",
    "                 payload = { 'class': bbox['class'], 'score': bbox['score'] })\n",
    "        for f in metadata\n",
    "        for bbox in f['bboxes']\n",
    "    ])\n",
    "    for video_file, metadata in zip([ 'driving1.mp4', 'driving2.mp4', 'driving3.mp4', 'driving4.mp4' ],\n",
    "                                    driving_metadata)\n",
    "})\n",
    "\n",
    "# Visualize bounding boxes with Vgrid\n",
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('bounding_boxes', bbox_ism.filter(lambda interval: interval['payload']['score'] > 0.9))\n",
    "    ]),\n",
    "    video_endpoint = 'https://olimar.stanford.edu/hdd/rekall_tutorials/basics/'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Walkthrough\n",
    "Now let's walk through the above code bit by bit to get an idea of what's going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Video metadata\n",
    "\n",
    "First we need to get some metadata about the individual videos that we're visualizing. In particular, we need to know the FPS, duration, width, and height of each video in order to display them using Vgrid. In our case, we've already computed these things for our driving videos, but you can also use [this script](https://github.com/scanner-research/esperlight/blob/master/create_video_metadata.py) to compute them for you (`fmpeg/ffprobe` are dependencies).\n",
    "\n",
    "### This code loads pre-computed FPS, duration, width, and height of each video and puts them into `VideoMetadata` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to disable warnings about olimar's certificate\n",
    "urllib3.disable_warnings()\n",
    "VIDEO_COLLECTION_BASEURL = \"https://olimar.stanford.edu/hdd/rekall_tutorials/basics/\"\n",
    "VIDEO_METADATA_FILENAME = 'video_metadata.json'\n",
    "\n",
    "metadata_json = requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME),\n",
    "                             verify=False).json()\n",
    "\n",
    "# Load video file metadata\n",
    "video_metadata = [\n",
    "    VideoMetadata(\n",
    "        v['filename'], id=v['filename'], fps=v['fps'],\n",
    "        num_frames=int(v['num_frames']), width=v['width'], height=v['height']\n",
    "    )\n",
    "    for v in metadata_json\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go line by line:\n",
    "\n",
    "Lines 2-4 specify the location of the metadata. You can look at the JSON file yourself by going to https://olimar.stanford.edu/hdd/rekall_tutorials/basics/.\n",
    "\n",
    "    urllib3.disable_warnings()\n",
    "    VIDEO_COLLECTION_BASEURL = \"https://olimar.stanford.edu/hdd/rekall_tutorials/basics/\"\n",
    "    VIDEO_METADATA_FILENAME = 'video_metadata.json'\n",
    "    \n",
    "Lines 6-7 get the data with an HTTP request and parse it into JSON:\n",
    "\n",
    "    metadata_json = requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME),\n",
    "                                 verify=False).json()\n",
    "\n",
    "At this point, `metadata_json` is a list of Python objects, with information about each video's filename, FPS, width, height, and number of frames. We can loop through this list and construct a list of `VideoMetadata` objects with that information:\n",
    "\n",
    "    video_metadata = [\n",
    "        VideoMetadata(\n",
    "            v['filename'], id=v['filename'], fps=v['fps'],\n",
    "            num_frames=v['num_frames'], width=v['width'], height=v['height']\n",
    "        )\n",
    "        for v in metadata_json\n",
    "    ]\n",
    "    \n",
    "`VideoMetadata` objects are constructed by passing in `path`, `id`, `fps`, `num_frames`, `width`, and `height`. The `path` is used by Vgrid and a fileserver to serve the video, and `id` is a key that links visual bounding box metadata to the videos. In this case, we use the path for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Visualizing videos directly.\n",
    "\n",
    "Now that we've loaded in video-level metadata, we can visualize the videos in Vgrid directly.\n",
    "\n",
    "#### Again, hover over videos and use `=` to expand the thumbnails. Then use `Shift-P` or `;` to play the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278935c66d1940acade2f15174928b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xd5U\\xc1n\\xa30\\x10\\xfd\\x95\\xc8\\xe7\\n\\x0c\\x98Rr\\xec…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = None, video_meta = video_metadata),\n",
    "    video_endpoint = 'https://olimar.stanford.edu/hdd/rekall_tutorials/basics/'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going line by line:\n",
    "\n",
    "Lines 1-5 specify a Vgrid spec for the widget:\n",
    "\n",
    "    vgrid_spec = VGridSpec(\n",
    "        video_meta = video_metadata,\n",
    "        vis_format = VideoBlockFormat(imaps = None, video_meta = video_metadata),\n",
    "        video_endpoint = 'https://olimar.stanford.edu/hdd/rekall_tutorials/basics/'\n",
    "    )\n",
    "    \n",
    "The `video_meta` option takes in a list of per-video metadata. `vis_format` specifies how the individual blocks in Vgrid should be drawn, along with what to draw on them. In this case, we are using `VideoBlockFormat` and passing in `None` for `imaps` and `video_metadata` for `video_meta`. This will automatically create one block for each video in `video_meta`. Later one, we'll see how we can use it to draw the spatial metadata as well. Finally, `video_endpoint` specifies that we should look for the videos on the `olimar` server.\n",
    "\n",
    "Finally, line 6 creates the widget and displays it in our Jupyter environment:\n",
    "\n",
    "    VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())\n",
    "    \n",
    "We pass the spec to the Vgrid widget as compressed JSON. Since it's the last line of the cell, it gets displayed below the cell automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bounding Boxes from JSON\n",
    "\n",
    "But as we saw earlier, we can do a lot more than just look at videos if we have some spatial metadata to associate with the videos.\n",
    "\n",
    "###  This code loads bounding box data associated with each video from olimar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_files = [ 'driving1.json', 'driving2.json', 'driving3.json', 'driving4.json' ]\n",
    "driving_metadata = [\n",
    "    requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, metadata_file),\n",
    "                 verify=False).json()\n",
    "    for metadata_file in metadata_files\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going line by line:\n",
    "\n",
    "Line 1 specifies the names of the metadata files on the server:\n",
    "\n",
    "    metadata_files = [ 'driving1.json', 'driving2.json', 'driving3.json', 'driving4.json' ]\n",
    "    \n",
    "In this case, we've pre-loaded bounding box metadata into `driving1.json`, `driving2.json`, etc. Each JSON file contains all the bounding boxes for the corresponding video (`driving1.mp4`, `driving2.mp4`, etc).\n",
    "\n",
    "Lines 2-6 make an HTTP request to the server and parse the JSON files:\n",
    "\n",
    "    driving_metadata = [\n",
    "        requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, metadata_file),\n",
    "                     verify=False).json()\n",
    "        for metadata_file in metadata_files\n",
    "    ]\n",
    "\n",
    "Line 3 specifies the path (join the base URL to the specific metadata file), and line 4 specifies that we should parse the file as JSON.\n",
    "\n",
    "If you manually inspect the parsed objects, you'll see that each one has the following format:\n",
    "\n",
    "    [\n",
    "        {\n",
    "            'video': string,\n",
    "            'frame': int,\n",
    "            'bboxes': [\n",
    "                {\n",
    "                    'class': string,\n",
    "                    'score': float,\n",
    "                    'x1': float,\n",
    "                    'x2': float,\n",
    "                    'y1': float,\n",
    "                    'y2': float\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    \n",
    "In other words, `driving_metadata[0][frame]['bboxes'][i]` contains Bbox `i` from frame `frame` in `driving1.mp4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'person',\n",
       " 'score': 0.17135410010814667,\n",
       " 'x1': 0.4788206100463867,\n",
       " 'x2': 0.4907509803771973,\n",
       " 'y1': 0.4826868693033854,\n",
       " 'y2': 0.5067381964789497}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_metadata[0][10]['bboxes'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bounding Boxes into Rekall\n",
    "\n",
    "Now that we've loaded our bounding boxes from JSON, we can load them into Rekall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2fps = { vm.id: vm.fps for vm in video_metadata }\n",
    "bbox_ism = IntervalSetMapping({\n",
    "    video_file: IntervalSet(\n",
    "        [\n",
    "            Interval(\n",
    "                Bounds3D(\n",
    "                    t1=f['frame'] / path2fps[video_file],\n",
    "                    t2=(f['frame'] + 1) / path2fps[video_file],\n",
    "                    x1=bbox['x1'], x2=bbox['x2'], y1=bbox['y1'], y2=bbox['y2']\n",
    "                ),\n",
    "                payload = { 'class': bbox['class'], 'score': bbox['score'] }\n",
    "            )\n",
    "            for f in metadata\n",
    "            for bbox in f['bboxes']\n",
    "        ]\n",
    "    )\n",
    "    for video_file, metadata in zip(\n",
    "        [ 'driving1.mp4', 'driving2.mp4', 'driving3.mp4', 'driving4.mp4' ],\n",
    "        driving_metadata\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains Rekall's core abstractions, so let's go line by line again.\n",
    "\n",
    "We loaded bounding boxes per-frame in JSON, but we'll need to convert their timestamps to seconds for Vgrid. Line 1 creates a mapping from video name to the FPS of the video:\n",
    "\n",
    "    path2fps = { vm.id: vm.fps for vm in video_metadata }\n",
    "\n",
    "Lines 2-21 creates an `IntervalSetMapping` containing all the bounding boxes:\n",
    "\n",
    "    bbox_ism = IntervalSetMapping({\n",
    "        video_file: IntervalSet(\n",
    "            [\n",
    "                Interval(\n",
    "                    Bounds3D(\n",
    "                        t1=f['frame'] / path2fps[video_file],\n",
    "                        t2=(f['frame'] + 1) / path2fps[video_file],\n",
    "                        x1=bbox['x1'], x2=bbox['x2'], y1=bbox['y1'], y2=bbox['y2']\n",
    "                    ),\n",
    "                    payload = { 'class': bbox['class'], 'score': bbox['score'] }\n",
    "                )\n",
    "                for f in metadata\n",
    "                for bbox in f['bboxes']\n",
    "            ]\n",
    "        )\n",
    "        for video_file, metadata in zip(\n",
    "            [ 'driving1.mp4', 'driving2.mp4', 'driving3.mp4', 'driving4.mp4' ],\n",
    "            driving_metadata\n",
    "        )\n",
    "    })\n",
    "    \n",
    "### The core abstraction of Rekall is an `Interval`, which contains a `Bounds` and a payload\n",
    "\n",
    "![videovolume](https://olimar.stanford.edu/hdd/rekall_tutorials/basics/videovolume.png)\n",
    "\n",
    "The `Bounds` contains 3D spatial co-ordinates, while the payload contains other metadata about each `Interval`; in this case, each `Interval` corresponds to a bounding box (`t1` and `t2` in seconds, spatial co-ordinates in co-ordinates relative to the frame size), and the payload contains class information and the confidence score for each bounding box:\n",
    "\n",
    "    Interval(\n",
    "        Bounds3D(\n",
    "            t1=f['frame'] / path2fps[video_file],\n",
    "            t2=(f['frame'] + 1) / path2fps[video_file],\n",
    "            x1=bbox['x1'], x2=bbox['x2'], y1=bbox['y1'], y2=bbox['y2']\n",
    "        ),\n",
    "        payload = { 'class': bbox['class'], 'score': bbox['score'] }\n",
    "    )\n",
    "    \n",
    "### An `IntervalSet` is a collection of related `Interval`s\n",
    "\n",
    "We create an `IntervalSet` by passing in a list of `Interval`s. In this case, we create an `IntervalSet` for each video by looping through each frame, and through all the bounding boxes for the frame:\n",
    "\n",
    "    IntervalSet(\n",
    "        [\n",
    "            Interval(\n",
    "                ...\n",
    "            )\n",
    "            for f in metadata\n",
    "            for bbox in f['bboxes']\n",
    "        ]\n",
    "    )\n",
    "\n",
    "### An `IntervalSetMapping` organizes `IntervalSet`s from different domains\n",
    "\n",
    "Finally, we organize `IntervalSet`s from different videos using an `IntervalSetMapping`, which maps from keys to `IntervalSet`. We create one by passing in a `dict`:\n",
    "\n",
    "    bbox_ism = IntervalSetMapping({\n",
    "        video_file: IntervalSet(\n",
    "            [\n",
    "                Interval(...)\n",
    "                for f in metadata\n",
    "                for bbox in f['bboxes']\n",
    "            ]\n",
    "        )\n",
    "        for video_file, metadata in zip(\n",
    "            [ 'driving1.mp4', 'driving2.mp4', 'driving3.mp4', 'driving4.mp4' ],\n",
    "            driving_metadata\n",
    "        )\n",
    "    })\n",
    "\n",
    "In this case, we are mapping from video name to the `IntervalSet` with that video's bounding boxes.\n",
    "\n",
    "#### Note that we are looping through the video names and JSON metadata together. This way, the keys of `bbox_ism` correspond to the IDs we set when we created `video_metadata`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display videos with bounding box metadata in Vgrid\n",
    "\n",
    "Finally, we can display the bounding box metadata drawn over the video metadata using Vgrid. To see more documentation about the Vgrid API, check out the [Vgrid documentation](https://github.com/scanner-research/vgrid#javascript-and-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cafc9047764b6eb53700c8bc6a9d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xbc\\xbd\\xdb\\xae\\xac\\xc9u\\xac\\xf7*B_s\\x13y>\\xf8\\xd2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize bounding boxes with Vgrid\n",
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('bounding_boxes', bbox_ism.filter(lambda interval: interval['payload']['score'] > 0.9))\n",
    "    ]),\n",
    "    video_endpoint = 'https://olimar.stanford.edu/hdd/rekall_tutorials/basics/'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, line by line:\n",
    "\n",
    "Lines 2-8 specify a VGridSpec for the widget:\n",
    "\n",
    "    vgrid_spec = VGridSpec(\n",
    "        video_meta = video_metadata,\n",
    "        vis_format = VideoBlockFormat(imaps = [\n",
    "            ('bounding_boxes', bbox_ism.filter(lambda interval: interval['payload']['score'] > 0.9))\n",
    "        ]),\n",
    "        video_endpoint = 'https://olimar.stanford.edu/hdd/rekall_tutorials/basics/'\n",
    "    )\n",
    "    \n",
    "This is the same as above, except this time we are passing `imaps` into `VideoBlockFormat`. This argument expects a list of pairs of `(String, IntervalSetMapping)`. In this case, we are only passing in a single `IntervalSetMapping` (and filtering out any bounding boxes whose score isn't high enough).\n",
    "\n",
    "Note that the ID's in `video_metadata` match the keys in the `bbox_ism` `IntervalSetMapping` that we created earlier. Vgrid uses this mapping to know what bounding boxes to draw on which videos.\n",
    "\n",
    "Line 9 passes the spec (with data) as compressed JSON and creates a VGrid Jupyter widget with the data. Since it's the last line of the cell, it gets displayed below the cell automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Multiple Tracks\n",
    "\n",
    "Now that we have a handle on visualizing `IntervalSetMapping`s with Vgrid, let's use some of Rekall's functionality to display a more meaningful visualization.\n",
    "\n",
    "## `IntervalSet` and `IntervalSetMapping` come with a number of useful set operations\n",
    "\n",
    "![set_operations](https://olimar.stanford.edu/hdd/rekall_tutorials/basics/set_operations.png)\n",
    "\n",
    "We've already used the `filter` operation above to filter out any bounding boxes whose score isn't high enough. We can use it again to get a number of different `IntervalSetMapping`s, each of which corresponds to different object categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = [\n",
    "    'person',\n",
    "    'car',\n",
    "    'truck',\n",
    "    'traffic light'\n",
    "]\n",
    "object_isms = [\n",
    "    bbox_ism.filter(lambda interval: interval['payload']['class'] == object_name)\n",
    "    for object_name in object_names\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a list of `IntervalSetMapping`s, each of which corresponds to a different object. The first `IntervalsetMapping` of `object_isms` contains all the bounding boxes with the `person` class, the second one contains all the bounding boxes with the `car` class, etc.\n",
    "\n",
    "This code visualizes the different `IntervalSetMapping`s. Each `IntervalSetMapping` will have a different track on the timeline and be visualized with a different color. Notice that we pass in more items into the `imaps` argument of `VideoBlockFormat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10550abc2b5495f955ced2ce3589087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xc4\\xbd\\xd9\\xce4=v\\xa5w+B\\x1d7^p\\x1e|\\xe8[\\xb0\\xcf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        (\n",
    "            object_name,\n",
    "            ism.filter(lambda interval: interval['payload']['score'] > 0.9)\n",
    "        )\n",
    "        for ism, object_name in zip(object_isms, object_names)\n",
    "    ]),\n",
    "    video_endpoint = 'https://olimar.stanford.edu/hdd/rekall_tutorials/basics/'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `IntervalSetMapping` operations to query for events\n",
    "\n",
    "Finally, we can use `IntervalSetMapping`'s built-in functions to query for events in our data. One particularly useful operation is joining two sets together to find interesting relationships between them:\n",
    "\n",
    "![simple_join](https://olimar.stanford.edu/hdd/rekall_tutorials/basics/simple_code.png)\n",
    "\n",
    "## Find people standing in front of cars\n",
    "\n",
    "We can use the `join` operation with some of Rekall's built-in predicates to find examples of people standing in front of cars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rekall.predicates import *\n",
    "person_ism = object_isms[0].filter(lambda interval: interval['payload']['score'] > 0.99)\n",
    "car_ism = object_isms[1].filter(lambda interval: interval['payload']['score'] > 0.99)\n",
    "person_in_front_of_cars = person_ism.join(\n",
    "    car_ism,\n",
    "    predicate = and_pred(\n",
    "        Bounds3D.T(equal()), # The pair have to be equal along the time dimension\n",
    "        Bounds3D.X(overlaps()), # The boxes overlap in the X dimension\n",
    "        Bounds3D.Y(overlaps()) # The boxes overlap in the Y dimension\n",
    "    ),\n",
    "    merge_op = lambda person, car: Interval(\n",
    "        person['bounds'].span(car['bounds']), # We use the \"span\" method of Bounds3D to get a spanning bound\n",
    "        payload = {\n",
    "            'class': 'person_overlap_car',\n",
    "            'score': person['payload']['score'] * car['payload']['score']\n",
    "        }\n",
    "    ),\n",
    "    window = 0.5 # Only look at pairs that differ by less than half a second from each other\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is worth breaking down further. Let's go line by line:\n",
    "\n",
    "Lines 4 and 5 establish that we are joining `person_ism` to `car_ism`. This will join every IntervalSet in `person_ism` to the right IntervalSet in `car_ism` (by the mapping key).\n",
    "\n",
    "    4   person_in_front_of_cars = person_ism.join(\n",
    "    5       car_ism,\n",
    "\n",
    "Lines 6-10 establish the predicate on pairs of joined Intervals.\n",
    "\n",
    "     6   predicate = and_pred(\n",
    "     7       Bounds3D.T(equal()), # The pair have to be equal along the time dimension\n",
    "     8       Bounds3D.X(overlaps()), # The boxes overlap in the X dimension\n",
    "     9       Bounds3D.Y(overlaps()) # The boxes overlap in the Y dimension\n",
    "    10   ),\n",
    "    \n",
    "`and_pred` is a predicate that computes a logical and between many predicates.\n",
    "\n",
    "`Bounds3D.T(equal())` is a one-dimensional predicate that says that a certain dimension (by default, (t1, t2), but we explicitly state it here for clarity) has to be equal between the two Intervals in the pair.\n",
    "\n",
    "`Bounds3D.X(overlaps())` is a one-dimensional predicate cast to the X dimension (default is the time dimension) and says that the two Intervals have to overlap in that dimension.\n",
    "\n",
    "`Bounds3D.Y(overlaps())` is a one-dimensional predicate cast to the Y dimension (default is the time dimension) and says that the two Intervals have to overlap in that dimension.\n",
    "\n",
    "See the Rekall documentation for more information about predicates.\n",
    "\n",
    "Lines 11-17 establish the merge_op to merge the pair of Intervals back to a single Interval.\n",
    "\n",
    "    11  merge_op = lambda person, car: Interval(\n",
    "    12      person['bounds'].span(car['bounds']), # We use the \"span\" method of Bounds3D to get a spanning bound\n",
    "    13      payload = {\n",
    "    14          'class': 'person_overlap_car',\n",
    "    15          'score': person['payload']['score'] * car['payload']['score']\n",
    "    16      }\n",
    "    17  ),\n",
    "    \n",
    "Line 11 establishes the arguments to the merge op - we take in two Intervals, coming from the IntervalSet on the left and the IntervalSet on the right of the join, respectively.\n",
    "\n",
    "    11   merge_op = lambda person, bicycle: Interval(\n",
    "Line 12 merges the bounds of the two of the two Intervals:\n",
    "\n",
    "    12      person['bounds'].span(car['bounds']), # We use the \"span\" method of Bounds3D to get a spanning bound\n",
    "\n",
    "We use the span method of Bounds3D to get the minimum Bounds spanning both Intervals.\n",
    "\n",
    "Lines 13-16 establish the new payload - a new class, whose score is the product of the constituent scores.\n",
    "\n",
    "    11      payload = {\n",
    "    12          'class': 'person_overlap_car',\n",
    "    13          'score': person['payload']['score'] * car['payload']['score']\n",
    "    14      }\n",
    "\n",
    "Finally, line 18 specifies that we should only look at pairs of Intervals that are overlapping or less than 0.5 seconds apart from each other in the time axis.\n",
    "\n",
    "    16  window = 0.5 # Only look at pairs that differ by less than half a second from each other\n",
    "    \n",
    "For more details, see the `IntervalSet` [documentation](https://rekallpy.readthedocs.io/en/latest/index.html#rekall.IntervalSet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096531c214d643538394bb75b197f57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xe5\\x9d]o\\\\\\xc7\\x91\\x86\\xffJ\\xc0\\xeb\\x80\\xee\\xef\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = VideoBlockFormat(imaps = [\n",
    "        ('person_car_overlap', person_in_front_of_cars)\n",
    "    ]),\n",
    "    video_endpoint = 'https://olimar.stanford.edu/hdd/rekall_tutorials/basics/'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize using `FlatFormat`\n",
    "\n",
    "### Results not great because of Vgrid bug (better with frameserver)\n",
    "\n",
    "Now we'll visualize our results using Vgrid again. Instead of visualizing each video in its own block, we can visualize each Interval in its own block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133d931cd515425d82dd121d6e52f6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xed]Mo\\x1c\\xc9\\x91\\xfd+\\x06\\xcf\\x06\\x95\\x11\\x99\\x1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgrid_spec = VGridSpec(\n",
    "    video_meta = video_metadata,\n",
    "    vis_format = FlatFormat(person_in_front_of_cars),\n",
    "    video_endpoint = 'https://olimar.stanford.edu/hdd/rekall_tutorials/basics/'\n",
    ")\n",
    "VGridWidget(vgrid_spec = vgrid_spec.to_json_compressed())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
